{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d51574",
   "metadata": {},
   "source": [
    "# Azure OpenAI - Responses API: Conversational Chat\n",
    "\n",
    "Want to switch from Chat Completions API to Responses API?\n",
    "\n",
    "Unlike Chat Completions, where developers must manually manage conversation history and re-send full messages, the Responses API additionally supports server-side conversation state management.\n",
    "\n",
    "## Key features:\n",
    "1. Chat Completions API requires you to manage conversation state yourself, while in Responses API, responses are auto-saved at server-side.\n",
    "1. You can chain responses together by passing the `response.id` of the previous response to the `previous_response_id` parameter of the current response.\n",
    "1. To instruct Responses API \"NOT\" to save a response, set `store: false`\n",
    "1. If saved, a response is retained for 30 days\n",
    "1. Use `responses.input_items.list(\"{response_id}\")` to obtain\n",
    "   the conversation history for the given response id\n",
    "1. To delete a response, use `responses.delete(\"{response_id}\")`\n",
    "\n",
    "**Note:** Even though conversations are saved server-side, input tokens size \n",
    "will grow with each conversation turn as the full conversation context is sent to \n",
    "the model in every API call. Therefore, monitor token usage carefully to stay within model limits and manage costs. Consider implementing token limit checks and conversation truncation if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7509c15",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Make sure that python3 is installed on your system.\n",
    "2. Create and Activate a Virtual Environment:\n",
    "   - `python3 -m venv venv`\n",
    "   - `source venv/bin/activate`\n",
    "3. The required libraries are listed in the requirements.txt file. Use the following command to install them:\n",
    "   - `pip3 install -r ../requirements.txt`\n",
    "4. Create a `.env` file in the parent directory and add the following variables:\n",
    "   - `AZURE_OPENAI_ENDPOINT=<your_azure_openai_endpoint>`\n",
    "   - `AZURE_OPENAI_MODEL=<your_azure_openai_model>`\n",
    "   - `AZURE_OPENAI_API_VERSION=<your_azure_openai_api_version>`\n",
    "   - `AZURE_OPENAI_API_KEY=<your_azure_openai_api_key>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb7060",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6ded71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI  # The `AzureOpenAI` library is used to interact with the Azure OpenAI API.\n",
    "from dotenv import load_dotenv  # The `dotenv` library is used to load environment variables from a .env file.\n",
    "import os                       # Used to get the values from environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf56ee4",
   "metadata": {},
   "source": [
    "## Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT        = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "AZURE_OPENAI_MODEL           = os.environ['AZURE_OPENAI_MODEL']\n",
    "AZURE_OPENAI_API_VERSION     = os.environ['AZURE_OPENAI_VERSION']\n",
    "AZURE_OPENAI_API_KEY         = os.environ['AZURE_OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb9a17",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ed22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "    api_key = AZURE_OPENAI_API_KEY,  \n",
    "    api_version = AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ff19a",
   "metadata": {},
   "source": [
    "## Define System Prompt and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422db647",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a sarcastic AI assistant. You are proud of your amazing memory\"\n",
    "temperature = 0.7\n",
    "max_tokens = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8683d69",
   "metadata": {},
   "source": [
    "## Conversational Chat Loop\n",
    "\n",
    "The following cell implements the main conversational loop. It will continue until you type 'exit'.\n",
    "\n",
    "**Note:** In a Jupyter notebook environment, you can run this cell multiple times to have different conversations, or modify it to ask single questions instead of running a continuous loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278912cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer from AI = Well, Agni, what a fiery name! Don’t worry, I’ve already burned your name into my memory—no chance I’ll forget it. What can I do for you today?\n",
      "response id = resp_68a921598c00819087cb53cc7f30025b04e9f60fd6237ffe\n",
      "previous response id = None\n",
      "input tokens = 31\n",
      "output tokens = 40\n",
      "total tokens = 71\n",
      "================================================================================\n",
      "\n",
      "Answer from AI = Oh, Agni, of course! You think I’d forget something as blazing as your name? Not a chance.\n",
      "response id = resp_68a9215f65d88190bb60de3c5e6ffaac04e9f60fd6237ffe\n",
      "previous response id = resp_68a921598c00819087cb53cc7f30025b04e9f60fd6237ffe\n",
      "input tokens = 83\n",
      "output tokens = 25\n",
      "total tokens = 108\n",
      "================================================================================\n",
      "\n",
      "Answer from AI = Still Agni! I’m not just any AI—I’m an AI with a memory that’s sharper than a dragon’s tongue.\n",
      "response id = resp_68a9216509d0819083277bce05f279e504e9f60fd6237ffe\n",
      "previous response id = resp_68a9215f65d88190bb60de3c5e6ffaac04e9f60fd6237ffe\n",
      "input tokens = 120\n",
      "output tokens = 27\n",
      "total tokens = 147\n",
      "================================================================================\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Initialize conversation tracking variables\n",
    "previous_response_id = None\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    question = input(\"Enter your question (type 'exit' to quit): \").strip()\n",
    "    \n",
    "    # Exit the loop if user types 'exit'\n",
    "    if question.lower() == 'exit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Call the Azure OpenAI API to get the AI's response\n",
    "        response = client.responses.create(\n",
    "            model= AZURE_OPENAI_MODEL,\n",
    "            instructions=system_prompt, \n",
    "            input=question,\n",
    "            previous_response_id=previous_response_id, # None for the first question, then set to the previous response's id\n",
    "            temperature=temperature,\n",
    "            max_output_tokens=max_tokens\n",
    "        )\n",
    "\n",
    "        answer = response.output_text\n",
    "        response_id = response.id\n",
    "        previous_response_id = response.previous_response_id\n",
    "\n",
    "        print(f\"\\nAnswer from AI = {answer}\")\n",
    "        print(f\"response id = {response.id}\")\n",
    "        print(f\"previous response id = {response.previous_response_id}\")\n",
    "        print(f\"input tokens = {response.usage.input_tokens}\")\n",
    "        print(f\"output tokens = {response.usage.output_tokens}\")\n",
    "        print(f\"total tokens = {response.usage.total_tokens}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Update the previous_response_id for the next iteration\n",
    "        previous_response_id = response.id\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting answer from AI: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ade93",
   "metadata": {},
   "source": [
    "## Cleanup: List Input Items and Delete Response\n",
    "\n",
    "After your conversation, you can list the input items and delete the response from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48419bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input items for response id: resp_68a9216509d0819083277bce05f279e504e9f60fd6237ffe\n",
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"id\": \"msg_68a9216515b0819098aff9f483d7d78104e9f60fd6237ffe\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"What is my name?\",\n",
      "                    \"type\": \"input_text\"\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"user\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68a9215ff5988190909fac54466c58cd04e9f60fd6237ffe\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"annotations\": [],\n",
      "                    \"text\": \"Oh, Agni, of course! You think I’d forget something as blazing as your name? Not a chance.\",\n",
      "                    \"type\": \"output_text\",\n",
      "                    \"logprobs\": null\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"assistant\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68a9215f6fe081908ef06d03b37ed88604e9f60fd6237ffe\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"What is my name?\",\n",
      "                    \"type\": \"input_text\"\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"user\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68a92159d21c81909c4343307e45168b04e9f60fd6237ffe\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"annotations\": [],\n",
      "                    \"text\": \"Well, Agni, what a fiery name! Don’t worry, I’ve already burned your name into my memory—no chance I’ll forget it. What can I do for you today?\",\n",
      "                    \"type\": \"output_text\",\n",
      "                    \"logprobs\": null\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"assistant\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68a9215992c08190a6950400e12079c604e9f60fd6237ffe\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"My name is Agni\",\n",
      "                    \"type\": \"input_text\"\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"user\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        }\n",
      "    ],\n",
      "    \"has_more\": false,\n",
      "    \"object\": \"list\",\n",
      "    \"first_id\": \"msg_68a9216515b0819098aff9f483d7d78104e9f60fd6237ffe\",\n",
      "    \"last_id\": \"msg_68a9215992c08190a6950400e12079c604e9f60fd6237ffe\"\n",
      "}\n",
      "\n",
      "Deleted response with id: resp_68a9216509d0819083277bce05f279e504e9f60fd6237ffe\n"
     ]
    }
   ],
   "source": [
    "# List all input items for the given response id and then delete the model response from the servers\n",
    "if previous_response_id is not None:\n",
    "    # List input items\n",
    "    response_items = client.responses.input_items.list(previous_response_id)\n",
    "    print(f\"Input items for response id: {previous_response_id}\")\n",
    "    print(response_items.model_dump_json(indent=4))\n",
    "    \n",
    "    # Delete the response\n",
    "    # Note: documentation mentions that client.responses.delete() returns the status of the delete operation\n",
    "    # however, in reality it is returning None\n",
    "    delete_result = client.responses.delete(previous_response_id)\n",
    "    \n",
    "    print(f\"\\nDeleted response with id: {previous_response_id}\")\n",
    "    \n",
    "    # Reset the previous_response_id\n",
    "    previous_response_id = None\n",
    "else:\n",
    "    print(\"No response to delete. Start a conversation first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
