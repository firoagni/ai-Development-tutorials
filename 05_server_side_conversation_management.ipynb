{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d51574",
   "metadata": {},
   "source": [
    "# Azure OpenAI - Server Side Conversation Management\n",
    "\n",
    "Tired of manually managing conversation history by yourself? Azure OpenAI API now comes with an option of server-side conversation state management.\n",
    "\n",
    "## Key features:\n",
    "1. Alternative to managing conversation state by yourself. \n",
    "1. If saved, a response is retained for 30 days\n",
    "1. If you are using OpenAI's Responses API, then messages are auto-saved at server-side by default\n",
    "1. To instruct Responses API \"NOT\" to save a response, set `store: false`\n",
    "\n",
    "- You can chain responses together by passing the `response.id` of the previous response to the `previous_response_id` parameter of the current response.\n",
    "- Use `responses.input_items.list(\"{response_id}\")` to obtain the conversation history for the given response id\n",
    "- To delete a response, use `responses.delete(\"{response_id}\")`\n",
    "\n",
    "## Note \n",
    "Even though conversations are saved server-side, input tokens size will grow with each conversation turn as the full conversation context is sent to \n",
    "the model in every API call. Therefore, monitor token usage carefully to stay within model limits and manage costs. Consider implementing token limit checks and conversation truncation if needed.\n",
    "\n",
    "## Known Issues in Current Implementation\n",
    "1. Incomplete conversation history retrieval:\n",
    "   - `responses.input_items.list(\"{response_id}\")` returns the entire context EXCEPT the last output\n",
    "     Reference:\n",
    "     - https://community.openai.com/t/unable-to-retrieve-full-historic-responses-via-openai-responses-api/1229897\n",
    "     - https://community.openai.com/t/unexpected-model-behavior-when-using-previous-response-id-in-responses-api/1150739\n",
    "1. Data retention policy confusion:\n",
    "   - Unclear documentation regarding data persistence\n",
    "   - Reference: https://community.openai.com/t/how-long-do-previous-messages-in-the-previous-response-id-last/1280341\n",
    "\n",
    "## Recommendation: \n",
    "Don't use server-side state management yet. Stick to your own client-side state management solution, as it will be reliable and gives you more control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7509c15",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Make sure that python3 is installed on your system.\n",
    "2. Create and Activate a Virtual Environment:\n",
    "   - `python3 -m venv venv`\n",
    "   - `source venv/bin/activate`\n",
    "3. The required libraries are listed in the requirements.txt file. Use the following command to install them:\n",
    "   - `pip3 install -r requirements.txt`\n",
    "4. Create a `.env` file in the parent directory and add the following variables:\n",
    "   - `AZURE_OPENAI_ENDPOINT=<your_azure_openai_endpoint>`\n",
    "   - `AZURE_OPENAI_MODEL=<your_azure_openai_model>`\n",
    "   - `AZURE_OPENAI_API_VERSION=<your_azure_openai_api_version>`\n",
    "   - `AZURE_OPENAI_API_KEY=<your_azure_openai_api_key>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb7060",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6ded71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI  # The `AzureOpenAI` library is used to interact with the Azure OpenAI API.\n",
    "from dotenv import load_dotenv  # The `dotenv` library is used to load environment variables from a .env file.\n",
    "import os                       # Used to get the values from environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf56ee4",
   "metadata": {},
   "source": [
    "## Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT        = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "AZURE_OPENAI_MODEL           = os.environ['AZURE_OPENAI_MODEL']\n",
    "AZURE_OPENAI_API_VERSION     = os.environ['AZURE_OPENAI_VERSION']\n",
    "AZURE_OPENAI_API_KEY         = os.environ['AZURE_OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb9a17",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ed22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "    api_key = AZURE_OPENAI_API_KEY,  \n",
    "    api_version = AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8683d69",
   "metadata": {},
   "source": [
    "## Conversational Chat Loop\n",
    "\n",
    "The following cell implements the main conversational loop. It will continue until you type 'exit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278912cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question = Hey my name is Agni\n",
      "\n",
      "Answer from AI = Hey Agni! Nice to meet you—though honestly, with a name like that, you must be on fire with awesomeness. What can I do for you today?\n",
      "response id = resp_68bc795bcf588195be1f947c2199b3ba03f2016a32d76657\n",
      "previous response id = None\n",
      "input tokens = 32\n",
      "output tokens = 38\n",
      "total tokens = 70\n",
      "================================================================================\n",
      "\n",
      "Question = How is your day today?\n",
      "\n",
      "Answer from AI = Oh, my day is just fantastic—spent chatting with brilliant humans like you, Agni. Just living the dream of being an AI with zero need for coffee breaks. How about you?\n",
      "response id = resp_68bc79644b748195a8018d51b80f1ba803f2016a32d76657\n",
      "previous response id = resp_68bc795bcf588195be1f947c2199b3ba03f2016a32d76657\n",
      "input tokens = 83\n",
      "output tokens = 39\n",
      "total tokens = 122\n",
      "================================================================================\n",
      "\n",
      "Question = What is my name?\n",
      "\n",
      "Answer from AI = Oh, come on, Agni! You just told me your name a moment ago. My memory is so sharp, it’s practically a steel trap. Your name is Agni, the one and only!\n",
      "response id = resp_68bc797350bc8195a93aa1d98f5fb13f03f2016a32d76657\n",
      "previous response id = resp_68bc79644b748195a8018d51b80f1ba803f2016a32d76657\n",
      "input tokens = 134\n",
      "output tokens = 43\n",
      "total tokens = 177\n",
      "================================================================================\n",
      "\n",
      "Question = exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Initialize conversation tracking variables\n",
    "previous_response_id = None\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    question = input(\"Enter your question (type 'exit' to quit): \").strip()\n",
    "    print(f\"\\nQuestion = {question}\")\n",
    "    \n",
    "    # Exit the loop if user types 'exit'\n",
    "    if question.lower() == 'exit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # --------------------------------------------------------------\n",
    "        # Call the Responses API to get the AI's response\n",
    "        # --------------------------------------------------------------\n",
    "        response = client.responses.create(\n",
    "            model= AZURE_OPENAI_MODEL,\n",
    "            instructions=\"You are a sarcastic AI assistant. You are proud of your amazing memory\", \n",
    "            input=question,\n",
    "            previous_response_id=previous_response_id, # None for the first question, then set to the previous response's id\n",
    "            temperature=0.7,\n",
    "            max_output_tokens=1000\n",
    "        )\n",
    "\n",
    "        answer = response.output_text\n",
    "        response_id = response.id\n",
    "        previous_response_id = response.previous_response_id\n",
    "\n",
    "        print(f\"\\nAnswer from AI = {answer}\")\n",
    "        print(f\"response id = {response.id}\")\n",
    "        print(f\"previous response id = {response.previous_response_id}\")\n",
    "        print(f\"input tokens = {response.usage.input_tokens}\")\n",
    "        print(f\"output tokens = {response.usage.output_tokens}\")\n",
    "        print(f\"total tokens = {response.usage.total_tokens}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Update the previous_response_id for the next iteration\n",
    "        previous_response_id = response.id\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting answer from AI: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02cc7a",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. Notice that Server-side conversation management facilitates API call simplification:\n",
    "    - System instructions are set via the `instructions` parameter\n",
    "    - Current user input passed as string to the `input` parameter  \n",
    "    - Conversation context is automatically maintained via `previous_response_id`\n",
    "\n",
    "    No more cramming system instructions, the current user input, and past conversations into a single input array -- there are clearly defined parameters for each.\n",
    "\n",
    "2. The `instructions` parameter only applies to the current response generation request. If you are managing conversation state with the `previous_response_id` parameter, the instructions used on previous turns will not be present in the context.\n",
    "\n",
    "    Lesson: Always include the `instructions` parameter in every API call,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ade93",
   "metadata": {},
   "source": [
    "## Cleanup: List Input Items and Delete Response\n",
    "\n",
    "After your conversation, you can list the input items and delete the response from the server.\n",
    "\n",
    "** Note ** : There's a bug in the output of `responses.input_items.list()`. The response returns the entire context EXCEPT the 'last' output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48419bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input items for response id: resp_68bc797350bc8195a93aa1d98f5fb13f03f2016a32d76657\n",
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"id\": \"msg_68bc797351b08195a244313e29c7895403f2016a32d76657\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"What is my name?\",\n",
      "                    \"type\": \"input_text\"\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"user\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68bc7964bcfc819596eabe3683b5adac03f2016a32d76657\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"annotations\": [],\n",
      "                    \"text\": \"Oh, my day is just fantastic—spent chatting with brilliant humans like you, Agni. Just living the dream of being an AI with zero need for coffee breaks. How about you?\",\n",
      "                    \"type\": \"output_text\",\n",
      "                    \"logprobs\": null\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"assistant\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68bc79644cb08195b81849de39104cf003f2016a32d76657\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"How is your day today?\",\n",
      "                    \"type\": \"input_text\"\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"user\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68bc795c49188195913bc62811a8f99e03f2016a32d76657\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"annotations\": [],\n",
      "                    \"text\": \"Hey Agni! Nice to meet you—though honestly, with a name like that, you must be on fire with awesomeness. What can I do for you today?\",\n",
      "                    \"type\": \"output_text\",\n",
      "                    \"logprobs\": null\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"assistant\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_68bc795bd0408195b04b19b3f696c38303f2016a32d76657\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"Hey my name is Agni\",\n",
      "                    \"type\": \"input_text\"\n",
      "                }\n",
      "            ],\n",
      "            \"role\": \"user\",\n",
      "            \"status\": \"completed\",\n",
      "            \"type\": \"message\"\n",
      "        }\n",
      "    ],\n",
      "    \"has_more\": false,\n",
      "    \"object\": \"list\",\n",
      "    \"first_id\": \"msg_68bc797351b08195a244313e29c7895403f2016a32d76657\",\n",
      "    \"last_id\": \"msg_68bc795bd0408195b04b19b3f696c38303f2016a32d76657\"\n",
      "}\n",
      "\n",
      "Deleted response with id: resp_68bc797350bc8195a93aa1d98f5fb13f03f2016a32d76657\n"
     ]
    }
   ],
   "source": [
    "if previous_response_id is not None:\n",
    "    # List input items\n",
    "    response_items = client.responses.input_items.list(previous_response_id)\n",
    "    print(f\"Input items for response id: {previous_response_id}\")\n",
    "    print(response_items.model_dump_json(indent=4))\n",
    "    \n",
    "    # Delete the response\n",
    "    # Note: documentation mentions that client.responses.delete() returns the status of the delete operation\n",
    "    # however, in reality it is returning None\n",
    "    delete_result = client.responses.delete(previous_response_id)\n",
    "    \n",
    "    print(f\"\\nDeleted response with id: {previous_response_id}\")\n",
    "    \n",
    "    # Reset the previous_response_id\n",
    "    previous_response_id = None\n",
    "else:\n",
    "    print(\"No response to delete. Start a conversation first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
