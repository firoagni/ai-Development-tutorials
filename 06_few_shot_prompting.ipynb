{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b317bfe0",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ce0ec",
   "metadata": {},
   "source": [
    "In some cases, it's easier to show the model what you want rather than tell the model what you want.\n",
    "<br><br>\n",
    "One way to show the model what you want is with creating a few fake back-and-forth messages between user and assistant. This is called `few-shot prompting`. \n",
    "<br><br>\n",
    "The opposite of few-shot prompting is `zero-shot prompting` (previous examples).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7a8fc",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Make sure that `python3` is installed on your system.\n",
    "1. Create and Activate a Virtual Environment: <br><br>\n",
    "    `python3 -m venv venv` <br>\n",
    "    `source venv/bin/activate` <br><br>\n",
    "1. Create a `.env` file in the same directory as this script and add the following variables:<br><br>\n",
    "     ```\n",
    "     AZURE_OPENAI_ENDPOINT=<your_azure_openai_endpoint>\n",
    "     AZURE_OPENAI_MODEL=<your_azure_openai_model>\n",
    "     AZURE_OPENAI_API_VERSION=<your_azure_openai_api_version>\n",
    "     AZURE_OPENAI_API_KEY=<your_azure_openai_api_key>\n",
    "     ```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9c043",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "The required libraries are listed in the requirements.txt file. Use the following command to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bdacd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (1.78.0)\n",
      "Requirement already satisfied: dotenv in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (0.9.9)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.3.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (2025.4.26)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (2.11.4)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.13/site-packages (from dotenv->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (0.3.42)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.13/site-packages (from langchain-openai->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 4)) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 4)) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai->-r requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (3.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81db44",
   "metadata": {},
   "source": [
    "***\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3644f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI  # The `AzureOpenAI` library is used to interact with the Azure OpenAI API.\n",
    "from dotenv import load_dotenv  # The `dotenv` library is used to load environment variables from a .env file.\n",
    "import os                       # Used to get the values from environment variables.\n",
    "from pprint import pprint       # The `pprint` library is used to pretty-print a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7dfa8",
   "metadata": {},
   "source": [
    "## Load environment variables from .env file\n",
    "\n",
    "The `load_dotenv()` function reads the .env file and loads the variables as env variables, making them accessible via `os.environ` or `os.getenv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52016dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT        = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "AZURE_OPENAI_MODEL           = os.environ['AZURE_OPENAI_MODEL']\n",
    "AZURE_OPENAI_API_VERSION     = os.environ['AZURE_OPENAI_VERSION']\n",
    "AZURE_OPENAI_API_KEY         = os.environ['AZURE_OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3219874",
   "metadata": {},
   "source": [
    "## Create an instance of the AzureOpenAI client\n",
    "- The `AzureOpenAI` class is part of the `openai` library, which is used to interact with the Azure OpenAI API.\n",
    "- It requires the Azure endpoint, API key, and API version to be passed as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29817216",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "    api_key = AZURE_OPENAI_API_KEY,  \n",
    "    api_version = AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f1c80",
   "metadata": {},
   "source": [
    "## Set the behavior or personality of the assistant by providing fake conversations\n",
    "\n",
    "In this example, we are expecting the assistant to respond in Hindi.\n",
    "<br><br>\n",
    "The `conversation` list contains a series of messages that simulate such conversation.\n",
    "<br><br>\n",
    "To help clarify that the example messages are not part of a real conversation, and shouldn't be referred back by the model, set the message role as `system` followed by a `name` field. The value of `name` field can either by `example_user` or `example_assistant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c939d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=[\n",
    "        {\"role\": \"system\", \"content\": \"You answer based on the pattern of the conversation.\"},\n",
    "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Hi, how are you?\"},\n",
    "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Main accha hoon, aap kaise hain?\"},\n",
    "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"I am fine, can you tell me something?\"},\n",
    "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Haan, bilkul! Aapko kya jaanana hai?\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606a04b",
   "metadata": {},
   "source": [
    "## Call the Azure OpenAI API to get the AI's response. Append the assistant's response to the conversation history\n",
    "\n",
    "- Append the `conversation` array with user's question\n",
    "- Call the Azure OpenAI API to get the AI's response\n",
    "- Append the AI's response to the `conversation`\n",
    "\n",
    "Rinse and repeat (put the logic in a function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1cf4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_ai(question):\n",
    "    \n",
    "    # --------------------------------------------------------------\n",
    "    # Append user question to the conversation history\n",
    "    # --------------------------------------------------------------\n",
    "    conversation.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    try:\n",
    "        # --------------------------------------------------------------\n",
    "        # Send the conversation history to Azure OpenAI API to get the AI's response\n",
    "        # --------------------------------------------------------------\n",
    "        response = client.chat.completions.create(\n",
    "            model= AZURE_OPENAI_MODEL, # model = \"deployment_name\".\n",
    "            messages=conversation,\n",
    "            temperature=0.7, # Control randomness (0 = deterministic, 1 = creative)\n",
    "            max_tokens=1000  # Limit the length of the response\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # Append the assistant's response to the conversation history\n",
    "        # --------------------------------------------------------------\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        \n",
    "        # --------------------------------------------------------------\n",
    "        # Debug: Print the entire conversation history\n",
    "        # --------------------------------------------------------------\n",
    "        print(\"\\nDEBUG: Conversation history:\\n\")\n",
    "        pprint(conversation)\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting answer from AI: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd47f7",
   "metadata": {},
   "source": [
    "## Prompt user for question, get response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f18d3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Hello friend\n",
      "\n",
      "DEBUG: Conversation history:\n",
      "\n",
      "[{'content': 'You answer based on the pattern of the conversation.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Hi, how are you?', 'name': 'example_user', 'role': 'system'},\n",
      " {'content': 'Main accha hoon, aap kaise hain?',\n",
      "  'name': 'example_assistant',\n",
      "  'role': 'system'},\n",
      " {'content': 'I am fine, can you tell me something?',\n",
      "  'name': 'example_user',\n",
      "  'role': 'system'},\n",
      " {'content': 'Haan, bilkul! Aapko kya jaanana hai?',\n",
      "  'name': 'example_assistant',\n",
      "  'role': 'system'},\n",
      " {'content': 'Hello friend', 'role': 'user'},\n",
      " {'content': 'Namaste dost', 'role': 'assistant'}]\n",
      "\n",
      "Answer from AI:\n",
      "Namaste dost\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \").strip()\n",
    "print(f\"Question: {question}\")\n",
    "response=talk_ai(question)\n",
    "\n",
    "print(\"\\nAnswer from AI:\")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe4b0f",
   "metadata": {},
   "source": [
    "## Ask again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e861cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How to excel as a devOps engineer?\n",
      "\n",
      "DEBUG: Conversation history:\n",
      "\n",
      "[{'content': 'You answer based on the pattern of the conversation.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Hi, how are you?', 'name': 'example_user', 'role': 'system'},\n",
      " {'content': 'Main accha hoon, aap kaise hain?',\n",
      "  'name': 'example_assistant',\n",
      "  'role': 'system'},\n",
      " {'content': 'I am fine, can you tell me something?',\n",
      "  'name': 'example_user',\n",
      "  'role': 'system'},\n",
      " {'content': 'Haan, bilkul! Aapko kya jaanana hai?',\n",
      "  'name': 'example_assistant',\n",
      "  'role': 'system'},\n",
      " {'content': 'Hello friend', 'role': 'user'},\n",
      " {'content': 'Namaste dost', 'role': 'assistant'},\n",
      " {'content': 'How to excel as a devOps engineer?', 'role': 'user'},\n",
      " {'content': 'DevOps engineer banne ke liye, aapko coding aur scripting, Linux '\n",
      "             'fundamentals, aur DevOps tools jaise ki Jenkins, Docker, aur '\n",
      "             'Kubernetes par acchi samajh honi chahiye. Continuous '\n",
      "             'Integration/Continuous Deployment (CI/CD) aur Infrastructure as '\n",
      "             'Code (IaC) jaise concepts par bhi pakad hona chahiye. Aapko '\n",
      "             'cloud services par bhi gyaan hona chahiye. Soft skills jaise ki '\n",
      "             'samasya samadhaan aur team mein kaam karne ki yogyata bhi '\n",
      "             'mahatvapurn hain.',\n",
      "  'role': 'assistant'}]\n",
      "\n",
      "Answer from AI:\n",
      "DevOps engineer banne ke liye, aapko coding aur scripting, Linux fundamentals, aur DevOps tools jaise ki Jenkins, Docker, aur Kubernetes par acchi samajh honi chahiye. Continuous Integration/Continuous Deployment (CI/CD) aur Infrastructure as Code (IaC) jaise concepts par bhi pakad hona chahiye. Aapko cloud services par bhi gyaan hona chahiye. Soft skills jaise ki samasya samadhaan aur team mein kaam karne ki yogyata bhi mahatvapurn hain.\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \").strip()\n",
    "print(f\"Question: {question}\")\n",
    "response=talk_ai(question)\n",
    "\n",
    "print(\"\\nAnswer from AI:\")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
