{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b317bfe0",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting\n",
    "https://platform.openai.com/docs/guides/prompt-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ce0ec",
   "metadata": {},
   "source": [
    "In some cases, it's easier to show the model what you want rather than tell the model what you want.\n",
    "<br><br>\n",
    "One way to show the model what you want is with creating a few fake back-and-forth messages between user and assistant. This is called `few-shot prompting`. \n",
    "<br><br>\n",
    "The opposite of few-shot prompting is `zero-shot prompting` (previous examples).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7a8fc",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Make sure that `python3` is installed on your system.\n",
    "1. Create and Activate a Virtual Environment: <br><br>\n",
    "    `python3 -m venv venv` <br>\n",
    "    `source venv/bin/activate` <br><br>\n",
    "1. Create a `.env` file in the same directory as this script and add the following variables:<br><br>\n",
    "     ```\n",
    "     AZURE_OPENAI_ENDPOINT=<your_azure_openai_endpoint>\n",
    "     AZURE_OPENAI_MODEL=<your_azure_openai_model>\n",
    "     AZURE_OPENAI_API_VERSION=<your_azure_openai_api_version>\n",
    "     AZURE_OPENAI_API_KEY=<your_azure_openai_api_key>\n",
    "     ```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9c043",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "The required libraries are listed in the requirements.txt file. Use the following command to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bdacd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (1.106.1)\n",
      "Requirement already satisfied: dotenv in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.9.9)\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (2.11.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.13/site-packages (from tiktoken->-r requirements.txt (line 2)) (2025.9.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.13/site-packages (from dotenv->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic->-r requirements.txt (line 5)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic->-r requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (0.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81db44",
   "metadata": {},
   "source": [
    "***\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3644f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI  # The `AzureOpenAI` library is used to interact with the Azure OpenAI API.\n",
    "from dotenv import load_dotenv  # The `dotenv` library is used to load environment variables from a .env file.\n",
    "import os                       # Used to get the values from environment variables.\n",
    "from pprint import pprint       # The `pprint` library is used to pretty-print a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7dfa8",
   "metadata": {},
   "source": [
    "## Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52016dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT        = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "AZURE_OPENAI_MODEL           = os.environ['AZURE_OPENAI_MODEL']\n",
    "AZURE_OPENAI_API_VERSION     = os.environ['AZURE_OPENAI_VERSION']\n",
    "AZURE_OPENAI_API_KEY         = os.environ['AZURE_OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3219874",
   "metadata": {},
   "source": [
    "## Create an instance of the AzureOpenAI client\n",
    "- The `AzureOpenAI` class is part of the `openai` library, which is used to interact with the Azure OpenAI API.\n",
    "- It requires the Azure endpoint, API key, and API version to be passed as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29817216",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "    api_key = AZURE_OPENAI_API_KEY,  \n",
    "    api_version = AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f1c80",
   "metadata": {},
   "source": [
    "## Set the behavior or personality of the assistant by providing fake conversations\n",
    "\n",
    "In this example, we are expecting the assistant to respond in Hindi.\n",
    "\n",
    "To achieve this, we will provide a series of examples in the `developer` message that simulate such conversation and instruct the model to answer based on the pattern of the conversation.\n",
    "\n",
    "For elaborate developer and user messages, OpenAI recommends using a combination of Markdown formatting and XML tags to help the model understand logical boundaries of your prompt and context data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c939d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_message = f\"\"\"\n",
    "# Instruction\n",
    "You answer based on the pattern of the conversation.\n",
    "\n",
    "# Examples\n",
    "<user_query id=\"example-1\">Hi, how are you?</user_query>\n",
    "<assistant_response id=\"example-1\">Main accha hoon, aap kaise hain?</assistant_response>\n",
    "<user_query id=\"example-2\">I am fine, can you tell me something?</user_query>\n",
    "<assistant_response id=\"example-2\">Haan, bilkul! Aapko kya jaanana hai?</assistant_response>\n",
    "\"\"\"\n",
    "conversation=[{\"role\": \"developer\", \"content\": llm_message}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606a04b",
   "metadata": {},
   "source": [
    "## Call the Responses API to get the AI's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb1cf4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_ai(question):\n",
    "    \n",
    "    # --------------------------------------------------------------\n",
    "    # Append user question to the conversation history\n",
    "    # --------------------------------------------------------------\n",
    "    conversation.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model= AZURE_OPENAI_MODEL,\n",
    "            input=conversation,\n",
    "            temperature=0.7,\n",
    "            max_output_tokens=1000\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # Extract answer and print it\n",
    "        # --------------------------------------------------------------\n",
    "        answer = response.output_text\n",
    "        print(f\"Answer from AI = {answer}\")\n",
    "        print(f\"input tokens = {response.usage.input_tokens}\")\n",
    "        print(f\"output tokens = {response.usage.output_tokens}\")\n",
    "        print(f\"total tokens = {response.usage.total_tokens}\")\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # Append the assistant's response to the conversation history\n",
    "        # --------------------------------------------------------------\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting answer from AI: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd47f7",
   "metadata": {},
   "source": [
    "## Prompt user for question, get response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f18d3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Hi! My name is Agni\n",
      "Answer from AI = Namaste Agni! Aap se milkar khushi hui. Aap kaise hain?\n",
      "input tokens = 125\n",
      "output tokens = 21\n",
      "total tokens = 146\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \").strip()\n",
    "print(f\"Question: {question}\")\n",
    "talk_ai(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe4b0f",
   "metadata": {},
   "source": [
    "## Ask again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e861cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How are you today?\n",
      "Answer from AI = Main aaj bahut achha hoon, dhanyavaad! Aap ka din kaisa ja raha hai?\n",
      "input tokens = 158\n",
      "output tokens = 26\n",
      "total tokens = 184\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \").strip()\n",
    "print(f\"Question: {question}\")\n",
    "talk_ai(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
